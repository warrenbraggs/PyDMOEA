from Utils import NSGAUtils, COEAUtils
from tqdm import tqdm
import random

class Evolution:

    def __init__(self, problem, n_individuals, n_generations, n_variables, min, max):
        """ Evolution class required to evolve the genetic algorithms. It contains 6 algorithms: NSGAII, COEA, DNSGAIIA, DNSGAIIB, DCOEAA, DCOEAB.

        Parameters
        ----------
        problem : Problem
            MOP/DMOP considered
        n_individuals : int
            Number of individuals
        n_generations : int
            Number of generations
        n_variables : int
            Number of variables
        min : int
            Minimum value generated by the functions
        max : int
            Maximum value generated by the functions
        """
        self.nsga = NSGAUtils(problem, n_individuals, n_generations, n_variables, min, max)
        self.coea = COEAUtils(problem, n_individuals, n_generations, n_variables, min, max)
        self.n_individuals = n_individuals
        self.n_generations = n_generations
        self.n_variables = n_variables

    def evolveNSGAII(self, population:list):
        """ Evolution of the NSGAII

        Parameters
        ----------
        population : list
            List of individuals

        Returns
        -------
        list
            Optimal set of solutions
        """        
        # Evaluate the individuals before performing the algorithm
        self.nsga.evaluate_objective_values(population,self.n_individuals)
        # Fast non dominated sorting to determine pareto optimal front
        pareto = self.nsga.fast_non_dominated_sort(population)

        # Initialisation of the distance list for crowding distance
        distance = [0] * len(pareto)
        
        # Iteration over the pareto optimal front list 
        for i in range(len(pareto)):
            # Crowding distance
            distance[i] = self.nsga.crowding_distance(pareto[i])


        # Creation of a child
        child = self.nsga.create_child(population)
        
        # Perform the algorithm until the ending criteria (number of generations)
        for i in tqdm (range (self.n_generations)):
            # Extend the population with the new child
            population.extend(child)            
            # Determine the pareto optimal front
            pareto = self.nsga.fast_non_dominated_sort(population)
            # Initialisation of the distance list for crowding distance
            distance = [0] * len(pareto)

            newPopulation = []
            
            # Calculate the new crowding distance
            for j in range(len(pareto)):
                if pareto[j]:
                    if len(newPopulation) + len(pareto[j]) < self.n_individuals:
                        distance[j] = self.nsga.crowding_distance(pareto[j])
                        # Extend the new population with the pareto optimal front values
                        newPopulation.extend(pareto[j])
                else:
                    break
        
            # Set the best value as last element of the list
            distance[j] = self.nsga.crowding_distance(pareto[j])
            # Sort the pareto optimal front according to the distance in ascending order 
            pareto[j].sort(key=lambda distance: distance, reverse=False) 
            
            # Extend the new population with the new values of the pareto optimal front
            newPopulation.extend(pareto[j][0:self.n_variables - len(newPopulation)])

            returned_pareto = pareto
            population = newPopulation

            # Determine the pareto optimal front for the next generation
            pareto = self.nsga.fast_non_dominated_sort(population)
            # Initialisation of the distance list for crowding distance for the next generation
            distance = [0] * len(pareto)
            # Calculate the new crowding distance
            for p in range(len(pareto)):
               distance[p] = self.nsga.crowding_distance(pareto[p])
            
            # Create a new child
            child = self.nsga.create_child(population) 
        
        # Normalize the pareto front obtained
        function = []
        for i in returned_pareto:
            for j in i:
                function.append(j)
        
        # Adapted from https://stackoverflow.com/questions/74232723/data-frame-normalization-center-0-solution-1-1
        for i in range(len(function)):
            function[i][1]/=2

        # Return the new population
        return function
    

    def evolveDNSGAIIA(self, population:list, n_solutions):
        """ Evolution of the DNSGAIIA

        Parameters
        ----------
        population : list
            List of individuals
        n_solutions : int
            Number of random solutions to be introduced

        Returns
        -------
        list
            Optimal set of solutions
        """        
        # Dynamic evolution rate used for the evolution
        # 10 is a fast environment (frequent changes)
        dynamic_evolution_rate = 10

        # Evaluate the individuals before performing the algorithm
        self.nsga.evaluate_objective_values(population,self.n_individuals)
        # Fast non dominated sorting to determine pareto optimal front
        pareto = self.nsga.fast_non_dominated_sort(population)

        # Initialisation of the distance list for crowding distance
        distance = [0] * len(pareto)
        
        # Iteration over the pareto optimal front list 
        for i in range(len(pareto)):
            # Crowding distance
            distance[i] = self.nsga.crowding_distance(pareto[i])


        # Creation of a child
        child = self.nsga.create_child(population)
       
                
        # Perform the algorithm until the ending criteria (number of generations)
        for i in tqdm (range (self.n_generations)):
            # Extend the population with the new child
            population.extend(child)            
            # Determine the pareto optimal front
            pareto = self.nsga.fast_non_dominated_sort(population)
            # Initialisation of the distance list for crowding distance
            distance = [0] * len(pareto)

            newPopulation = []

            # Calculate the new crowding distance
            for j in range(len(pareto)):
                if pareto[j]:
                    if len(newPopulation) + len(pareto[j]) < self.n_individuals:
                        distance[j] = self.nsga.crowding_distance(pareto[j])
                        # Extend the new population with the pareto optimal front values
                        newPopulation.extend(pareto[j])
                else:
                    break
        

            # Set the best value as last element of the list
            distance[j] = self.nsga.crowding_distance(pareto[j])
            # Sort the pareto optimal front according to the distance in ascending order 
            pareto[j].sort(key=lambda distance: distance, reverse=False) 
            
            # Extend the new population with the new values of the pareto optimal front
            newPopulation.extend(pareto[j][0:self.n_variables - len(newPopulation)])

            returned_pareto = pareto
            population = newPopulation

            # Determine the pareto optimal front for the next generation
            pareto = self.nsga.fast_non_dominated_sort(population)
            # Initialisation of the distance list for crowding distance for the next generation
            distance = [0] * len(pareto)
            # Calculate the new crowding distance
            for p in range(len(pareto)):
               distance[p] = self.nsga.crowding_distance(pareto[p])
            
            # Create a new child
            child = self.nsga.create_child(population)            

            # Fast Changing environment
            if i % dynamic_evolution_rate == 1:
                # Generate random solutions
                temp_population = self.nsga.generate_random_solutions(n_solutions)
                # Calculate the objective values of the individuals 
                obj = self.nsga.calculate_objective_values(temp_population, n_solutions)
                # Replace an individual with the random individual
                population = self.nsga.replace_element(population, obj, n_solutions) 
        

        # Normalize the pareto front obtained
        function = []
        for i in returned_pareto:
            for j in i:
                function.append(j)
        
        # Adapted from https://stackoverflow.com/questions/74232723/data-frame-normalization-center-0-solution-1-1 
        # ratio for normalization
        coef = 0.3
        for i in range(len(function)):
            function[i][1]  = (function[i][1] - coef)

        # Return the new population
        return function
    
    
    def evolveDNSGAIIB(self, population:list, n_solutions):
        """ Evolution of the DNSGAIIB

        Parameters
        ----------
        population : list
            List of individuals
        n_solutions : int
            Number of random solutions to be introduced

        Returns
        -------
        list
            Optimal set of solutions
        """        
        # Dynamic evolution rate used for the evolution
        # 50 is a slow environment (few changes)
        dynamic_evolution_rate = 50

        # Evaluate the individuals before performing the algorithm
        self.nsga.evaluate_objective_values(population,self.n_individuals)
        # Fast non dominated sorting to determine pareto optimal front
        pareto = self.nsga.fast_non_dominated_sort(population)

        # Initialisation of the distance list for crowding distance
        distance = [0] * len(pareto)
        
        # Iteration over the pareto optimal front list 
        for i in range(len(pareto)):
            # Crowding distance
            distance[i] = self.nsga.crowding_distance(pareto[i])

        # Initialisation of the pool of children that will contain the mutated solutions
        children = []

        # Creation of a child
        child = self.nsga.create_child(population)
        children.extend(child)

        # Perform the algorithm until the ending criteria (number of generations)
        for i in tqdm (range (self.n_generations)):
            # Extend the population with the new child
            population.extend(child)            
            # Determine the pareto optimal front
            pareto = self.nsga.fast_non_dominated_sort(population)
            # Initialisation of the distance list for crowding distance
            distance = [0] * len(pareto)

            newPopulation = []

            # Calculate the new crowding distance
            for j in range(len(pareto)):
                if pareto[j]:
                    if len(newPopulation) + len(pareto[j]) < self.n_individuals:
                        distance[j] = self.nsga.crowding_distance(pareto[j])
                        # Extend the new population with the pareto optimal front values
                        newPopulation.extend(pareto[j])
                else:
                    break
        

            # Set the best value as last element of the list
            distance[j] = self.nsga.crowding_distance(pareto[j])
            # Sort the pareto optimal front according to the distance in ascending order 
            pareto[j].sort(key=lambda distance: distance, reverse=False) 
            
            # Extend the new population with the new values of the pareto optimal front
            newPopulation.extend(pareto[j][0:self.n_variables - len(newPopulation)])

            returned_pareto = pareto
            population = newPopulation

            # Determine the pareto optimal front for the next generation
            pareto = self.nsga.fast_non_dominated_sort(population)
            # Initialisation of the distance list for crowding distance for the next generation
            distance = [0] * len(pareto)
            # Calculate the new crowding distance
            for p in range(len(pareto)):
               distance[p] = self.nsga.crowding_distance(pareto[p])
            
            # Create a new child
            child = self.nsga.create_child(population) 
            # Add the child to the pool
            children.extend(child)
             

            # Fast Changing environment
            if i % dynamic_evolution_rate == 1:
                # Replace an individual with a mutated child from the pool of children
                population = self.nsga.replace_child(population, children, n_solutions)         
        
        # Normalize the pareto front obtained
        function = []
        y = []
        for i in returned_pareto:
            for j in i:
                function.append(j)
                y.append(j[1])

        min_v = min(y)         
        
        # Adapted from https://stackoverflow.com/questions/74232723/data-frame-normalization-center-0-solution-1-1
        for i in range(len(function)):
            function[i][1] = (function[i][1] - min_v) * (self.n_variables/2)
            function[i][0] = (function[i][0] - min_v) * (self.n_variables)

        # Return the new population
        return function

    
    def evolveCOEA(self, population, n_splits):
        """ Evolution of COEA

        Parameters
        ----------
        population : list
            List of individuals
        n_splits : int
            Number of splits

        Returns
        -------
        list
            Set of optimal solutions
        """        
        n_c = 100 # distribution index for crossver
        eta = 100 # mutation probability

        # Split the population in n equal parts
        subpopulations = self.coea.split_populations(population, n_splits)

        # Get the fitness value
        n_fitness = int(self.coea.get_fitness())

        # Create a new population
        newPopulation = []

        # Iterate untill the stopping criteria is reached
        for i in tqdm (range(n_fitness)):
            # Every 10 iterations, call the competitive process
            if i % 10 == 0:
                temp = self.coea.competitive_process(subpopulations)    
                # Extend the population with the new individuals
                newPopulation.extend(self.coea.calculate_objective_values(temp, len(temp)))
                
                # Shuffle subpopulation individuals
                random.shuffle(newPopulation)
                # Choose 2 random parents
                parent1 = random.choice(newPopulation)
                parent2 = random.choice(newPopulation)
                # Crossover
                child = self.coea.sbx(parent1, parent2, n_c)
                # Mutation
                child[0] = self.coea.polynomial_mutation(child[0], eta)
                child[1] = self.coea.polynomial_mutation(child[1], eta)

            else:		
                # Execute the cooperative process
                newPopulation.extend(self.coea.cooperative_process(subpopulations)) 
                # create_child includes Tournment, SBX and Mutation			
                child = self.coea.create_child(newPopulation)             

        #Update the new population
        newPopulation.extend(self.coea.cooperative_process(subpopulations))
        
        
        # Normalization
        function = []
        y = []
        for i in range(len(newPopulation)):
            function.append(newPopulation[i])
            y.append(function[i][1])
            
        min_v = min(y)

        # Adapted from https://stackoverflow.com/questions/74232723/data-frame-normalization-center-0-solution-1-1
        for i in range(len(function)):
            function[i][1] = function[i][1] - min_v
        
        # Return the new population
        return function


    def evolveDCOEAA(self, population, n_splits, sc_ratio):
        """ Evolution of DCOEAA

        Parameters
        ----------
        population : lit
            List of individuals
        n_splits : int
            Number of splits
        sc_ratio : int
            Number of stochastic solutions

        Returns
        -------
        list
            Set of optimal solutions
        """        
        n_c = 100 # distribution index for crossver
        eta = 100 # mutation probability

        # Split the population in n parts using the method
        subpopulations = self.coea.split_populations(population, n_splits)

        # Get the fitness value
        n_fitness = int(self.coea.get_fitness())

        # Create a new population
        newPopulation = []

        # Iterate untill the stopping criteria is reached
        for i in tqdm (range(n_fitness)):
            # Every 10 iterations, call the competitive process
            if i % 10 == 0:
                temp = self.coea.competitive_process(subpopulations)    
                # Extend the population with the new individuals
                newPopulation.extend(self.coea.calculate_objective_values(temp, len(temp)))
                
                # Shuffle subpopulation individuals
                random.shuffle(newPopulation)
                # Choose 2 random parents
                parent1 = random.choice(newPopulation)
                parent2 = random.choice(newPopulation)
                # Crossover
                child = self.coea.sbx(parent1, parent2, n_c)
                # Mutation
                child[0] = self.coea.polynomial_mutation(child[0], eta)
                child[1] = self.coea.polynomial_mutation(child[1], eta)
                # Evaluate the objective values used for the dynamic evolution
                temp_obj = self.coea.evaluate_objective_values(newPopulation, len(newPopulation))

            else:		
                # Execute the cooperative process
                newPopulation.extend(self.coea.cooperative_process(subpopulations)) 
                # create_child includes Tournment, SBX and Mutation			
                child = self.coea.create_child(newPopulation)   
                # Evaluate the objective values used for the dynamic evolution     
                temp_obj = self.coea.evaluate_objective_values(newPopulation, len(newPopulation))

            # Diversity via Stochastic Competitors
            # Evaluate the current individuals
            obj = self.coea.evaluate_objective_values(newPopulation, len(newPopulation)) 
            # Check if the competitve/cooperative mechanism generate the same objective value in comparison to the current individuals           
            if obj is temp_obj:
                # Introduce the competitive rocess
                temp = self.coea.competitive_process(subpopulations)  
                # Add the new individuals
                newPopulation.extend(self.coea.calculate_objective_values(temp, len(temp)))

                # Remove a subpopulation
                subpopulations.pop()
                # Add the stochastic competitors based on the sc_ratio
                subpopulations.append(self.coea.generate_random_solutions(sc_ratio))


        #Update the new population
        newPopulation.extend(self.coea.cooperative_process(subpopulations))
        #Return the new population
        return newPopulation


    def evolveDCOEAB(self, population, n_splits):
        """ Evolution of DCOEAB

        Parameters
        ----------
        population : list
            List of individuals
        n_splits : int
            Number of splits

        Returns
        -------
        list
            Set of optimal solutions
        """
        n_c = 100 # distribution index for crossver
        eta = 100 # mutation probability        

        # Split the population in n parts using the method
        subpopulations = self.coea.split_populations(population, n_splits)

        # Get the fitness value
        n_fitness = int(self.coea.get_fitness())

        # Create a new population
        newPopulation = []

        # Iterate untill the stopping criteria is reached
        for i in tqdm (range(n_fitness)):
            # Every 10 iterations, call the competitive process
            if i % 10 == 0:
                temp = self.coea.competitive_process(subpopulations) 
                # Extend the population with the new individuals   
                newPopulation.extend(self.coea.calculate_objective_values(temp, len(temp)))
                
               # Shuffle subpopulation individuals
                random.shuffle(newPopulation)
                # Choose 2 random parents
                parent1 = random.choice(newPopulation)
                parent2 = random.choice(newPopulation)
                # Crossover
                child = self.coea.sbx(parent1, parent2, n_c)
                # Mutation
                child[0] = self.coea.polynomial_mutation(child[0], eta)
                child[1] = self.coea.polynomial_mutation(child[1], eta)

            else:		
                # Execute the cooperative process
                newPopulation.extend(self.coea.cooperative_process(subpopulations)) 
                # create_child include Tournment, SBX and Mutation			
                child = self.coea.create_child(newPopulation)

            # Temporal Archive Update fast evolving environment (every iteration)
            if i > 0:
                # Determine the best solutions from the archive
                best_solutions = self.coea.temporal_archive_update(newPopulation)
                for j in newPopulation:
                    if j == best_solutions[0]:
                        # Remove from the population the dominant solutions
                        newPopulation.remove(j)
                        # Determine parent 1
                        if i % 2 == 0:
                            parent1 = best_solutions[0]
                        # Determine parent 2
                        if i % 2 == 1:
                            parent2 = best_solutions[0]
                            # Crossover with the new parents
                            child = self.coea.sbx(parent1, parent2, n_c)
                            child[0] = self.coea.polynomial_mutation(child[0], eta)
                            child[1] = self.coea.polynomial_mutation(child[1], eta)
                            # Add the new individuals to the population
                            newPopulation.extend(self.coea.calculate_objective_values(child, len(child)))
                    
        #Update and Return Archive
        newPopulation.extend(self.coea.cooperative_process(subpopulations))

        # Normalization
        # Adapted from https://stackoverflow.com/questions/74232723/data-frame-normalization-center-0-solution-1-1
        function = []
        y = []
        for i in range(len(newPopulation)):
            function.append(newPopulation[i])
            y.append(newPopulation[i][1])
  
        min_v = min(y)
        coef = 3
        for i in range(len(function)):
            function[i][1] = function[i][1] - (min_v*coef)            

        return function
